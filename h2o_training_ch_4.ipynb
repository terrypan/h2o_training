{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 4 - Deep learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binding and merging data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h2o\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "h2o.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# http://data.h2o.ai/\n",
    "url = \"https://s3.amazonaws.com/h2o-training/sparkling-water/allyears2k_headers.csv.gz\"\n",
    "data = h2o.import_file(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, valid, test = data.split_frame([0.8, 0.1], seed = 69)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"%d/%d/%d\" % (train.nrows, valid.nrows, test.nrows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2 = data[1:35255,:]\n",
    "train2 = h2o.assign(train2, \"first35255\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h2o.ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.ncol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = data[:,0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airports = data[:,[\"Origin\", \"Dest\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates.ncol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airports.ncol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use cbind to join (\"bind\") columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_and_d = airports.cbind(dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_and_d.dim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use rbind to join rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "restored_data = train.rbind([valid, test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "restored_data.dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "restored_data[:,0:4].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[:,0:4].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[:,0:4].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use h2o.merge() to join tables together when they have +1 columns in common"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Unline cbind() they can have diff. number of rows, and\n",
    "##### unlike rbind() they can have diff. number of columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Learning - Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://s3.amazonaws.com/h2o-training/sparkling-water/allyears2k_headers.csv.gz\"\n",
    "data = h2o.import_file(url)\n",
    "train, valid, test = data.split_frame([0.8, 0.1], seed = 69)\n",
    "print(\"%d/%d/%d\" % (train.nrows, valid.nrows, test.nrows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = \"IsArrDelayed\"\n",
    "ignoreFields = [\n",
    "    \"ArrDelay\", \"DepDelay\",\n",
    "    \"CarrierDelay\", \"WeatherDelay\",\n",
    "    \"NASDelay\", \"SecurityDelay\",\n",
    "    \"LateAircraftDelay\", \n",
    "    \"IsDepDelayed\", \"IsArrDelayed\",\n",
    "    \"ActualElapsedTime\" # But CRSElapsedTime is fine\n",
    "    \"ArrTime\" # But CRSArrTime is fine\n",
    "]\n",
    "xAll = [i for i in train.names if i not in ignoreFields]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from h2o.estimators.deeplearning import H2ODeepLearningEstimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_def = H2ODeepLearningEstimator()\n",
    "%time m_def.train(xAll, y, train, validation_frame = valid) # e.g. 61s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_def.model_performance(test) # e.g. MSE of 0.132, error of 0.2002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_def.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_200_epochs = H2ODeepLearningEstimator(epochs = 200,\n",
    "                                       stopping_rounds = 5, #Default\n",
    "                                       stopping_tolerance = 0, #Default\n",
    "                                       stopping_metric = \"logloss\" #Indirectly the default\n",
    "                                       )\n",
    "%time m_200_epochs.train(xAll, y, train, validation_frame = valid) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_200_epochs.model_performance(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_200_epochs.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_200_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_200x200x200 = H2ODeepLearningEstimator(epochs = 200,\n",
    "                # same early stopping (default)\n",
    "                hidden = [200,200,200]\n",
    "                )\n",
    "%time m_200x200x200.train(xAll, y, train, validation_frame = valid) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_200x200x200.model_performance(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_200x200x200.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_400x400 = = H2ODeepLearningEstimator(epochs = 200,\n",
    "                # same early stopping (default)\n",
    "                hidden = [400,400]\n",
    "                )\n",
    "%time m_400x400.train(xAll, y, train, validation_frame = valid) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "m_400x400.model_performance(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "m_400x400.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why did 400x400 take longer than 200x200x200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_def.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_def.summary()[\"units\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(3801 * 200) + (200 * 200) + (200 * 2) # Plus 200 + 200 + 2 biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_200x200x200.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_200x200x200.summary()[\"units\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_400x400.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_400x400.summary()[\"units\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.nlevels() # enum cardinality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.structure()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Models without that high-cardinality column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2 = list(filter(lambda v: v != 'TailNum', xAll))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m2_def = H2ODeepLearningEstimator()\n",
    "%time m2_def.train(x2, y, train, validation_frame = valid) # e.g. 13s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m2_200_epochs = H2ODeepLearningEstimator(epochs = 200,\n",
    "                                       stopping_rounds = 5, #Default\n",
    "                                       stopping_tolerance = 0, #Default\n",
    "                                       stopping_metric = \"logloss\" #Indirectly the default\n",
    "                                       )\n",
    "%time m2_200_epochs.train(x2, y, train, validation_frame = valid) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m2_200x200x200 = H2ODeepLearningEstimator(epochs = 200,\n",
    "                # same early stopping (default)\n",
    "                hidden = [200,200,200]\n",
    "                )\n",
    "%time m2_200x200x200.train(x2, y, train, validation_frame = valid) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m2_400x400 = H2ODeepLearningEstimator(epochs = 200,\n",
    "                # same early stopping (default)\n",
    "                hidden = [400,400]\n",
    "                )\n",
    "%time m2_400x400.train(x2, y, train, validation_frame = valid) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_models = [m_def, m2_def, m_200_epochs, m2_200_epochs, \n",
    "             m_200x200x200, m2_200x200x200, m_400x400, m2_400x400]\n",
    "\n",
    "loglosses = map(lambda x: x.logloss(), all_models)\n",
    "print(\"    defaults: %.4f --> %.4f\\n  200 epochs: %.4f --> %.4f\\n 200x3: %.4f --> %.4f\\n  400x2: %.4f --> %.4f\\n\" % loglosses)\n",
    "\n",
    "mse = map(lambda x: x.mse(), all_models)\n",
    "print(\"    defaults: %.4f --> %.4f\\n  200 epochs: %.4f --> %.4f\\n 200x3: %.4f --> %.4f\\n  400x2: %.4f --> %.4f\\n\" % mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_400x400.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning with Grids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning (Regression)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
